{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f89314",
   "metadata": {
    "papermill": {
     "duration": 0.003095,
     "end_time": "2025-08-16T05:29:47.261847",
     "exception": false,
     "start_time": "2025-08-16T05:29:47.258752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Guide To Extracting Data from the Movies Dataset\n",
    "\n",
    "This is a guide to *how to extract data from the imdb movies dataset*. This is one way of doing things. In this notebook I extract the data from the different *csv* files. They were seperate for a practical reasons in the data scraping phase. I also add some normalization and data cleaning. I am doing the bare minimum in terms of cleaning and normalization so it wouldn't be very complex.\n",
    "\n",
    "There is another notebook that is meant for a whole data cleaning process. You can check it out.\n",
    "\n",
    "## Introducing the Dataset and its structure\n",
    "\n",
    "This dataset provides annual data for the most popular 500–600 movies per year from 1920 to 2025, extracted from IMDb. It includes over 60,000 movies, spanning more than 100 years of cinematic history.\n",
    "\n",
    "Each year’s data is divided into three CSV files for flexibility and ease of use:\n",
    "- ``imdb_movies_[year].csv``: Basic movie details.\n",
    "- ``advanced_movies_details_[year]``.csv: Comprehensive metadata and financial details.\n",
    "- ``merged_movies_data_[year].csv``: A unified dataset combining both files.\n",
    "\n",
    "## What we are doing exactly:\n",
    "\n",
    "1. Merge all `merged_movies_data_{year}` files across all years into one csv.\n",
    "2. Change names to uniform naming style.\n",
    "3. Extract the `id`.\n",
    "4. Remove Duplicates\n",
    "5. Change Empty values to None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e79ab5",
   "metadata": {
    "papermill": {
     "duration": 0.002201,
     "end_time": "2025-08-16T05:29:47.266856",
     "exception": false,
     "start_time": "2025-08-16T05:29:47.264655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3 style=\"font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; color: #2c3e50; margin-top: 40px;\">Contact Me</h3>\n",
    "\n",
    "<p style=\"font-size: 16px; color: #555;\">\n",
    "  If you notice anything lacking, spot an issue with this notebook, or have suggestions for improvements, feel free to reach out through any of the platforms below:\n",
    "</p>\n",
    "\n",
    "<table style=\"font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; border-collapse: collapse; width: 100%; max-width: 600px;\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td style=\"padding: 10px;\">\n",
    "        <a href=\"https://www.linkedin.com/in/addalaraed/\" target=\"_blank\">\n",
    "          <img src=\"https://img.shields.io/badge/LinkedIn-Raed_Addala-blue?style=for-the-badge&logo=linkedin\" alt=\"LinkedIn Badge\"/>\n",
    "        </a>\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"padding: 10px;\">\n",
    "        <a href=\"https://x.com/AddalaRaed\" target=\"_blank\">\n",
    "          <img src=\"https://img.shields.io/badge/Twitter-@AddalaRaed-1DA1F2?style=for-the-badge&logo=twitter\" alt=\"Twitter Badge\"/>\n",
    "        </a>\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"padding: 10px;\">\n",
    "        <a href=\"mailto:addala.raed@gmail.com\">\n",
    "          <img src=\"https://img.shields.io/badge/Gmail-addala.raed@gmail.com-D14836?style=for-the-badge&logo=gmail\" alt=\"Gmail Badge\"/>\n",
    "        </a>\n",
    "      </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"padding: 10px;\">\n",
    "        <a href=\"https://github.com/RaedAddala\" target=\"_blank\">\n",
    "          <img src=\"https://img.shields.io/badge/GitHub-RaedAddala-181717?style=for-the-badge&logo=github\" alt=\"GitHub Badge\"/>\n",
    "        </a>\n",
    "      </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d03fc",
   "metadata": {
    "papermill": {
     "duration": 0.002116,
     "end_time": "2025-08-16T05:29:47.271324",
     "exception": false,
     "start_time": "2025-08-16T05:29:47.269208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Organization and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b4c92",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-16T05:29:47.277140Z",
     "iopub.status.busy": "2025-08-16T05:29:47.276832Z",
     "iopub.status.idle": "2025-08-16T05:29:48.915033Z",
     "shell.execute_reply": "2025-08-16T05:29:48.914130Z"
    },
    "papermill": {
     "duration": 1.643036,
     "end_time": "2025-08-16T05:29:48.916679",
     "exception": false,
     "start_time": "2025-08-16T05:29:47.273643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ed456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T05:29:48.923137Z",
     "iopub.status.busy": "2025-08-16T05:29:48.922767Z",
     "iopub.status.idle": "2025-08-16T05:29:48.926433Z",
     "shell.execute_reply": "2025-08-16T05:29:48.925835Z"
    },
    "papermill": {
     "duration": 0.008289,
     "end_time": "2025-08-16T05:29:48.927783",
     "exception": false,
     "start_time": "2025-08-16T05:29:48.919494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/kaggle/input/imdb-movies-from-1960-to-2023/Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfac5dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T05:29:48.933566Z",
     "iopub.status.busy": "2025-08-16T05:29:48.933301Z",
     "iopub.status.idle": "2025-08-16T05:29:48.938156Z",
     "shell.execute_reply": "2025-08-16T05:29:48.937505Z"
    },
    "papermill": {
     "duration": 0.009008,
     "end_time": "2025-08-16T05:29:48.939310",
     "exception": false,
     "start_time": "2025-08-16T05:29:48.930302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605347b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T05:29:48.945359Z",
     "iopub.status.busy": "2025-08-16T05:29:48.945116Z",
     "iopub.status.idle": "2025-08-16T05:29:58.336363Z",
     "shell.execute_reply": "2025-08-16T05:29:58.335513Z"
    },
    "papermill": {
     "duration": 9.396311,
     "end_time": "2025-08-16T05:29:58.338097",
     "exception": false,
     "start_time": "2025-08-16T05:29:48.941786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder in os.listdir(root_dir):\n",
    "    folder_path = os.path.join(root_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.startswith(\"merged_movies_data_\") and file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                data = pd.read_csv(file_path)\n",
    "\n",
    "                column_mapping = {\n",
    "                    'Title': 'title',\n",
    "                    'Year': 'year',\n",
    "                    'Duration': 'duration',\n",
    "                    'MPA': 'MPA',\n",
    "                    'Rating': 'rating',\n",
    "                    'Votes': 'votes',\n",
    "                    'méta_score': 'meta_score',\n",
    "                    'description': 'description',\n",
    "                    'Movie Link': 'movie_link',\n",
    "                    'link': 'movie_link',\n",
    "                    'writers': 'writers',\n",
    "                    'directors': 'directors',\n",
    "                    'stars': 'stars',\n",
    "                    'budget': 'budget',\n",
    "                    'opening_weekend_Gross': 'opening_weekend_gross',\n",
    "                    'grossWorldWWide': 'gross_worldwide',\n",
    "                    'gross_US_Canada': 'gross_us_canada',\n",
    "                    'Release_date': 'release_date',\n",
    "                    'countries_origin': 'countries_origin',\n",
    "                    'filming_locations': 'filming_locations',\n",
    "                    'production_company': 'production_companies',\n",
    "                    'awards_content': 'awards_content',\n",
    "                    'genres': 'genres',\n",
    "                    'Languages': 'languages'\n",
    "                }\n",
    "                data = data.rename(columns={k: v for k, v in column_mapping.items() if k in data.columns})\n",
    "\n",
    "                # Clean the title column: remove leading numbers and trim whitespace\n",
    "                data['title'] = data['title'].apply(lambda x: re.sub(r'^\\d+\\.\\s*', '', str(x)).strip())\n",
    "\n",
    "                def parse_release_date(x):\n",
    "                    try:\n",
    "                        return parser.parse(str(x), fuzzy=True).date()\n",
    "                    except (parser.ParserError, TypeError, ValueError):\n",
    "                        return pd.NaT\n",
    "\n",
    "                data['release_date'] = data['release_date'].apply(parse_release_date)\n",
    "                if 'year' in data.columns:\n",
    "                    data['year'] = pd.to_numeric(data['year'])\n",
    "                    data['release_date'] = data.apply(\n",
    "                        lambda row: pd.to_datetime(f\"{int(row['year'])}-01-01\") if pd.isna(row['release_date']) and not pd.isna(row['year']) else row['release_date'],\n",
    "                        axis=1\n",
    "                    )\n",
    "                    # Drop the year column\n",
    "                    data = data.drop(columns=['year'])\n",
    "\n",
    "                # Clean the Movie_Link column\n",
    "                data['movie_link'] = data['movie_link'].apply(lambda x: re.sub(r'/\\?ref_=.*$', '', str(x)))\n",
    "\n",
    "                # Extract and add the id field from Movie_Link\n",
    "                data['id'] = data['movie_link'].apply(lambda x: x.split('/')[-1] if '/' in str(x) else None)\n",
    "\n",
    "                # Check for duplicate IDs and keep only one row per ID\n",
    "                duplicate_ids = data[data.duplicated(subset=['id'], keep=False)]\n",
    "                if not duplicate_ids.empty:\n",
    "                    print(\"Duplicate IDs found:\")\n",
    "                    print(print(duplicate_ids[['id', 'title']]))\n",
    "                data = data.drop_duplicates(subset=['id'], keep='last')\n",
    "\n",
    "                # Replace empty arrays with null\n",
    "                fields_to_check = [\n",
    "                    'directors', 'writers', 'stars', 'genres', 'countries_origin',\n",
    "                    'filming_locations', 'production_companies', 'languages'\n",
    "                ]\n",
    "                for field in fields_to_check:\n",
    "                    if field in data.columns:\n",
    "                        data[field] = data[field].apply(lambda x: None if pd.isna(x) or str(x).strip() == '[]' else x).astype(\"object\")\n",
    "\n",
    "                merged_data = pd.concat([merged_data, data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81effffa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T05:29:58.344864Z",
     "iopub.status.busy": "2025-08-16T05:29:58.344168Z",
     "iopub.status.idle": "2025-08-16T05:29:58.356017Z",
     "shell.execute_reply": "2025-08-16T05:29:58.355166Z"
    },
    "papermill": {
     "duration": 0.016226,
     "end_time": "2025-08-16T05:29:58.357170",
     "exception": false,
     "start_time": "2025-08-16T05:29:58.340944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_data_issues(df):\n",
    "    issues = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_issues = {}\n",
    "        \n",
    "        # Count NaN values\n",
    "        nans = df[col].isna().sum()\n",
    "        if nans > 0:\n",
    "            col_issues['NaN_count'] = int(nans)\n",
    "\n",
    "        # Count +inf and -inf (only for numeric types)\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            inf_count = np.isinf(df[col]).sum()\n",
    "            if inf_count > 0:\n",
    "                col_issues['inf_count'] = int(inf_count)\n",
    "\n",
    "        if col_issues:\n",
    "            issues[col] = col_issues\n",
    "\n",
    "    return issues\n",
    "\n",
    "problems = detect_data_issues(data)\n",
    "\n",
    "if problems:\n",
    "    print(\"⚠️ Issues detected in dataset:\")\n",
    "    for col, issue in problems.items():\n",
    "        print(f\" - {col}: {issue}\")\n",
    "else:\n",
    "    print(\"✅ No NaN/inf issues found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b429251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T05:29:58.363210Z",
     "iopub.status.busy": "2025-08-16T05:29:58.362983Z",
     "iopub.status.idle": "2025-08-16T05:29:58.395258Z",
     "shell.execute_reply": "2025-08-16T05:29:58.394626Z"
    },
    "papermill": {
     "duration": 0.036908,
     "end_time": "2025-08-16T05:29:58.396755",
     "exception": false,
     "start_time": "2025-08-16T05:29:58.359847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_order = ['id', 'title'] + [col for col in merged_data.columns if col not in ['id', 'title']]\n",
    "merged_data = merged_data[columns_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519b939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T05:29:58.403390Z",
     "iopub.status.busy": "2025-08-16T05:29:58.402740Z",
     "iopub.status.idle": "2025-08-16T05:29:58.430274Z",
     "shell.execute_reply": "2025-08-16T05:29:58.429553Z"
    },
    "papermill": {
     "duration": 0.031981,
     "end_time": "2025-08-16T05:29:58.431511",
     "exception": false,
     "start_time": "2025-08-16T05:29:58.399530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Merged data shape: {merged_data.shape}\")\n",
    "display(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8adda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T05:29:58.438757Z",
     "iopub.status.busy": "2025-08-16T05:29:58.438495Z",
     "iopub.status.idle": "2025-08-16T05:30:00.298880Z",
     "shell.execute_reply": "2025-08-16T05:30:00.298187Z"
    },
    "papermill": {
     "duration": 1.865593,
     "end_time": "2025-08-16T05:30:00.300394",
     "exception": false,
     "start_time": "2025-08-16T05:29:58.434801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data.to_csv('/kaggle/working/final_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6427301,
     "sourceId": 11180157,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.017642,
   "end_time": "2025-08-16T05:30:00.821204",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-16T05:29:42.803562",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
